<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>eye tracking | NeurophysiCole</title>
    <link>https://neurophysicole.com/tag/eye-tracking/</link>
      <atom:link href="https://neurophysicole.com/tag/eye-tracking/index.xml" rel="self" type="application/rss+xml" />
    <description>eye tracking</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© 2020</copyright><lastBuildDate>Thu, 13 Aug 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://neurophysicole.com/media/npc_logo</url>
      <title>eye tracking</title>
      <link>https://neurophysicole.com/tag/eye-tracking/</link>
    </image>
    
    <item>
      <title>Classifying Expertise from Eye Movement Data</title>
      <link>https://neurophysicole.com/project/expertise_eye_tracking/</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://neurophysicole.com/project/expertise_eye_tracking/</guid>
      <description>&lt;p&gt;Expertise can be defined by many different criteria. Sometimes there is an absolute threshold for expertise (i.e., certification), and other times expertise is judged in relative terms (i.e., comparing years of experience between two individuals). Being able to define expertise can be useful in numerous situations. Most notably for me, is the potential application of human assistive technology being able to anticipate the type of support individuals will need based on their level of expertise.&lt;/p&gt;
&lt;p&gt;Take a second to imagine a scenario where you are teaching yourself a skill by participating in automated online computer tutorials. For instance, learning how to program. Now, say the computer is capable of monitoring your eye movements and determining how well you are progressing through the program - not based purely on performance, but based on where you focus your attention externally! Eye movements are one of many behaviors that can signal to the world (in an albeit subtle fashion) what you are thinking about. This kind of technology has the potential to advance the science of learning by highlighting important eye movement features that may be indicative of the cognitive processes relied on by experts. Furthermore, developing human assistive technology in this domain has the potential to improve learning trajectories and advance performance at a level that was possible in the past.&lt;/p&gt;
&lt;p&gt;All this said, we are still at square one with trying to determine the most effective method for detecting expertise from behavior. Dr. Mike Dodd, Josh Zosky, and I are working in collaboration with computer scientist Dr. Bonita Sharif to determine the best method for determining expertise from the eye movements of programmers actively working to debug computer software.&lt;/p&gt;
&lt;h2 id=&#34;collaborators&#34;&gt;Collaborators&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://neurophysicole.com/author/michael-d.-dodd-phd/&#34;&gt;Mike Dodd, PhD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bonita Sharif, PhD&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://neurophysicole.com/author/joshua-e.-zosky/&#34;&gt;Josh Zosky&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;status&#34;&gt;Status&lt;/h2&gt;
&lt;p&gt;The manuscript for this project is currently in progress.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Decoding Eye Movement Data</title>
      <link>https://neurophysicole.com/project/deepeye/</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://neurophysicole.com/project/deepeye/</guid>
      <description>&lt;p&gt;Imagine a world where a computer could determine what you were thinking about by simply monitoring your eye movements. Scary, right? Well it turns out that if you have individuals look at the same image, but ask them to evaluate different characteristics of the image (e.g., &lt;em&gt;determine the age of the individuals in the image&lt;/em&gt;, or &lt;em&gt;name the individuals in the image&lt;/em&gt;.), the scan paths created by their eye movements have been shown to visibly differ between tasks. We&amp;rsquo;re exploring the most efficient and effective methods for making that happen! (But don&amp;rsquo;t worry, mind-reading robots are still very far off.)&lt;/p&gt;
&lt;p&gt;We are working to teach the computer to use eye movement data to determine what an individual is thinking. More specifically, in this project we had participants search, rate, or memorize scene images while their eye movements were recorded. Then we fed a deep convolutional neural network the eye movement data formatted as a timeline (coordinates and pupil size), and as an image snapshot of each trial which was then categorized. Typically, classification models are built on a cognitive or neurobiological foundation. At the moment, we are interested in exploring the ability of a black box model to decode eye movement data using no explicit theoretical justiciation in the development of our model. Our models were developed using the deep learning toolbox, 
&lt;a href=&#34;http://delineate.it&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DeLINEATE&lt;/a&gt;, developed by members of Dr. Johnson&amp;rsquo;s lab. Moving forward, we will continue to explore this neural network approach to decoding eye movement data, and other related questions concerning both theoretical and applied purposes.&lt;/p&gt;
&lt;h2 id=&#34;collaborators&#34;&gt;Collaborators&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://neurophysicole.com/author/matthew-r.-johnson-phd/&#34;&gt;Matt Johnson, PhD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://neurophysicole.com/author/michael-d.-dodd-phd/&#34;&gt;Mike Dodd, PhD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Karl Kuntzelman, PhD&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;status&#34;&gt;Status&lt;/h2&gt;
&lt;p&gt;The manuscript for this project is currently under review.&lt;/p&gt;
&lt;h2 id=&#34;pre-print&#34;&gt;Pre Print&lt;/h2&gt;
&lt;p&gt;Cole, Z. J., Kuntzelman, K., Dodd, M. D., &amp;amp; Johnson, M. (2020, September 23). Convolutional neural networks can decode eye movement data: A black box approach to predicting task from eye movements. 
&lt;a href=&#34;https://doi.org/10.31234/osf.io/5a6jm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.31234/osf.io/5a6jm&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;published-abstract&#34;&gt;Published Abstract&lt;/h2&gt;
&lt;p&gt;This work has been presented at the 
&lt;a href=&#34;https://www.visionsciences.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vision Sciences Society Annual Convention&lt;/a&gt; in 2019. The conference proceedings were published in the &lt;em&gt;Journal of Vision&lt;/em&gt;. Find the abstract 
&lt;a href=&#34;https://jov.arvojournals.org/article.aspx?articleid=2751172&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
